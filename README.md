# CyberBully_ML


Problem Statement:

The increasing prevalence of cyberbullying on social media platforms like Twitter has become a significant concern. The anonymity and ease of access provided by these platforms have made it easier for individuals to engage in harmful behaviors, such as posting offensive or harmful comments. These comments can range in severity, from age-related insults (level 1), gender-based harassment (level 2), religious discrimination (level 3), sexual harassment (level 4), to explicit threats or hate speech (level 5). 

The challenge is to develop a machine learning model that can accurately identify and categorize these comments based on their severity level. The model should be able to analyze the content of a comment and determine whether it violates any guidelines. If a comment is categorized as level 4 or 5, the system should automatically send an email to the cybersecurity cell, alerting them of the violation. 

This solution aims to provide a proactive approach to combating cyberbullying, ensuring a safer and more inclusive environment for all users. The effectiveness of the model will be measured by its accuracy in correctly identifying and categorizing comments, as well as its efficiency in alerting the cybersecurity cell.
